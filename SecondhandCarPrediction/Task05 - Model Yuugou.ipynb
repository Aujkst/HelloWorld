{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型融合 (Model Yuugou)\n",
    "\n",
    "Yuugou？？？哈哈哈最近刷日剧有点上头\n",
    "\n",
    "### Bagging\n",
    "    - Reduces variance and increases accuracy\n",
    "    - Robust against outliers or noisy data\n",
    "    - Often used with Decision Trees\n",
    "### Boosting \n",
    "    - Also reduces varience and increases accuracy\n",
    "    - NOT robust against outliers or noisy data\n",
    "    - Flexible - can be used with any loss function\n",
    "### Stacking \n",
    "    - Used to ensemble a diverse group of strong learners\n",
    "    - Involves training a second-level ML algorithm called a \"metalearner\" \n",
    "      to learn theoptimal combination of the base learners"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Regression Problem (Stacking)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking_method(train_reg1, train_reg2, train_reg3, y_train_true, \n",
    "                    test_pre1, test_pre2, test_pre3, \n",
    "                    model_L2= linear_model.LinearRegression()):\n",
    "    \n",
    "    model_L2.fit(pd.concat([pd.Series(train_reg1), \n",
    "                            pd.Series(train_reg2), \n",
    "                            pd.Series(train_reg3)], axis = 1).values, \n",
    "                 y_train_true)\n",
    "    \n",
    "    Stacking_result = model_L2.predict(pd.concat([pd.Series(test_pre1), \n",
    "                                                  pd.Series(test_pre2), \n",
    "                                                  pd.Series(test_pre3)], axis = 1).values)\n",
    "    \n",
    "    return Stacking_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 生成数据\n",
    "\n",
    "train_reg1 = [3.2, 8.2, 9.1, 5.2]\n",
    "train_reg2 = [2.9, 8.1, 9.0, 4.9]\n",
    "train_reg3 = [3.1, 7.9, 9.2, 5.0]\n",
    "\n",
    "y_train_true = [3, 8, 9, 5] \n",
    "\n",
    "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
    "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
    "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
    "\n",
    "y_test_true = [1, 3, 2, 6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Stacking_pre MAE: 0.042134831460675204\n"
    }
   ],
   "source": [
    "model_L2= linear_model.LinearRegression()\n",
    "\n",
    "Stacking_pre = Stacking_method(train_reg1, train_reg2, train_reg3, y_train_true,\n",
    "                               test_pre1, test_pre2, test_pre3, model_L2)\n",
    "\n",
    "print('Stacking_pre MAE:', metrics.mean_absolute_error(y_test_true, Stacking_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加权平均\n",
    "\n",
    "def Weighted_method(test_pre1, test_pre2, test_pre3, w=[1/3,1/3,1/3]):\n",
    "    \n",
    "    Weighted_result = w[0]*pd.Series(test_pre1) + w[1]*pd.Series(test_pre2) + w[2]*pd.Series(test_pre3)\n",
    "    \n",
    "    return Weighted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Weighted_pre MAE: 0.05750000000000027\nStacking_pre MAE: 0.042134831460675204\n"
    }
   ],
   "source": [
    "w = [0.3,0.4,0.3] # 权重\n",
    "\n",
    "Weighted_pre = Weighted_method(test_pre1, test_pre2, test_pre3, w)\n",
    "\n",
    "print('Weighted_pre MAE:',metrics.mean_absolute_error(y_test_true, Weighted_pre))\n",
    "print('Stacking_pre MAE:', metrics.mean_absolute_error(y_test_true, Stacking_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Classification Problem"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Mechanism "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Majority Voting**: \n",
    "\n",
    "The final output class label is the one that receives more than half of the votes.\n",
    "\n",
    "- **Plurality Voting**: \n",
    "\n",
    "It takes the class label which receives the largest number of votesas the final winner.\n",
    "\n",
    "- **Weighting Voting**: \n",
    "\n",
    "It gives more power to the stronger classifiers in voting.\n",
    "\n",
    "- **Soft Voting**: \n",
    "\n",
    "For individual classifiers which produce class probability outputs\n",
    "\n",
    "(from *Ensemble Methods: Foundations and Algorithms*)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "\n",
    "clf1 = XGBClassifier(learning_rate = 0.1, n_estimators = 150, \n",
    "                     max_depth = 3, min_child_weight = 2, subsample = 0.7,\n",
    "                     colsample_bytree = 0.6, objective = 'binary:logistic')\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_samples_split=4,\n",
    "                              min_samples_leaf = 63, oob_score = True)\n",
    "\n",
    "clf3 = SVC(C = 0.1, gamma = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.96 (+/- 0.02) [XGBBoosting]\nAccuracy: 0.33 (+/- 0.00) [Random Forest]\nAccuracy: 0.95 (+/- 0.03) [SVM]\nAccuracy: 0.95 (+/- 0.03) [Ensemble]\n"
    }
   ],
   "source": [
    "# 硬投票\n",
    "\n",
    "eclf_hard = VotingClassifier(estimators = [('xgb', clf1), ('rf', clf2), ('svc', clf3)], \n",
    "                             voting = 'hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf_hard], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
    "    \n",
    "    scores = cross_val_score(clf, x, y, cv = 5, scoring = 'accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.96 (+/- 0.02) [XGBBoosting]\nAccuracy: 0.33 (+/- 0.00) [Random Forest]\nAccuracy: 0.95 (+/- 0.03) [SVM]\nAccuracy: 0.96 (+/- 0.02) [Ensemble]\n"
    }
   ],
   "source": [
    "# 软投票\n",
    "\n",
    "clf3 = SVC(C = 0.1, probability = True, gamma = 'auto')\n",
    "\n",
    "eclf_soft = VotingClassifier(estimators = [('xgb', clf1), ('rf', clf2), ('svc', clf3)], \n",
    "                             voting = 'soft', weights = [2, 1, 1])\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf_soft], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
    "    \n",
    "    scores = cross_val_score(clf, x, y, cv = 5, scoring = 'accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "\n",
    "data_0 = iris.data\n",
    "data = data_0[:100,:]\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    "\n",
    "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [LogisticRegression(solver = 'lbfgs'),\n",
    "        RandomForestClassifier(n_estimators = 5, n_jobs = -1, criterion = 'gini'),\n",
    "        ExtraTreesClassifier(n_estimators = 5, n_jobs = -1, criterion = 'gini'),\n",
    "        ExtraTreesClassifier(n_estimators = 5, n_jobs = -1, criterion = 'entropy'),\n",
    "        GradientBoostingClassifier(learning_rate = 0.05, subsample = 0.5, max_depth = 6, n_estimators = 5)]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "val auc Score: 1.000000\nval auc Score: 0.500000\nval auc Score: 0.500000\nval auc Score: 0.500000\nval auc Score: 0.500000\n"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits)\n",
    "skf = skf.split(X, y)\n",
    "\n",
    "# skf是一个generator\n",
    "for j, clf in enumerate(clfs):\n",
    "\n",
    "    dataset_blend_test_j = np.zeros((X_predict.shape[0], 5))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "        dataset_blend_train[test, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]\n",
    "\n",
    "    # 对于测试集，直接用这k个模型的预测值均值作为新的特征。\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_blend_test[:, j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Val auc Score of Stacking: 1.000000\n"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver = 'lbfgs')\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "print(\"Val auc Score of Stacking: %f\" % (roc_auc_score(y_predict, y_submission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}